{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Cross Validation and K-Fold Exercice"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Importing the libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Importing the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "X_train, X_text, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Verify if is necessary to apply feature scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "               0           1           2            3           4   \\\ncount  455.000000  455.000000  455.000000   455.000000  455.000000   \nmean    14.067213   19.247363   91.557407   648.541099    0.096167   \nstd      3.499380    4.405291   24.149231   344.944564    0.013458   \nmin      6.981000    9.710000   43.790000   143.500000    0.062510   \n25%     11.635000   16.000000   74.720000   415.650000    0.086475   \n50%     13.270000   18.820000   85.980000   541.800000    0.095660   \n75%     15.740000   21.710000  103.700000   770.050000    0.104850   \nmax     28.110000   39.280000  188.500000  2499.000000    0.144700   \n\n               5           6           7           8           9   ...  \\\ncount  455.000000  455.000000  455.000000  455.000000  455.000000  ...   \nmean     0.103869    0.089193    0.048344    0.180618    0.062820  ...   \nstd      0.053522    0.081747    0.038925    0.028074    0.007159  ...   \nmin      0.019380    0.000000    0.000000    0.106000    0.049960  ...   \n25%      0.063750    0.028010    0.020220    0.161750    0.057685  ...   \n50%      0.090970    0.059990    0.032630    0.178100    0.061440  ...   \n75%      0.130100    0.132200    0.073820    0.195300    0.066250  ...   \nmax      0.345400    0.426800    0.201200    0.304000    0.097440  ...   \n\n               20          21          22           23          24  \\\ncount  455.000000  455.000000  455.000000   455.000000  455.000000   \nmean    16.177226   25.647297  106.625297   869.026593    0.132329   \nstd      4.770020    6.225470   33.195053   552.926912    0.022550   \nmin      7.930000   12.020000   50.410000   185.200000    0.071170   \n25%     13.010000   21.090000   83.715000   513.900000    0.115950   \n50%     14.910000   25.400000   97.590000   683.400000    0.131400   \n75%     18.550000   29.370000  124.950000  1033.500000    0.146200   \nmax     33.130000   49.540000  229.300000  3432.000000    0.218400   \n\n               25          26          27          28          29  \ncount  455.000000  455.000000  455.000000  455.000000  455.000000  \nmean     0.254329    0.276578    0.113904    0.290865    0.083945  \nstd      0.159882    0.215937    0.066784    0.064624    0.018408  \nmin      0.027290    0.000000    0.000000    0.156500    0.055040  \n25%      0.145850    0.107900    0.063390    0.249400    0.071835  \n50%      0.211600    0.229800    0.097220    0.281900    0.079930  \n75%      0.336800    0.385300    0.162500    0.320100    0.092070  \nmax      1.058000    1.252000    0.291000    0.663800    0.207500  \n\n[8 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>455.000000</td>\n      <td>455.000000</td>\n      <td>455.000000</td>\n      <td>455.000000</td>\n      <td>455.000000</td>\n      <td>455.000000</td>\n      <td>455.000000</td>\n      <td>455.000000</td>\n      <td>455.000000</td>\n      <td>455.000000</td>\n      <td>...</td>\n      <td>455.000000</td>\n      <td>455.000000</td>\n      <td>455.000000</td>\n      <td>455.000000</td>\n      <td>455.000000</td>\n      <td>455.000000</td>\n      <td>455.000000</td>\n      <td>455.000000</td>\n      <td>455.000000</td>\n      <td>455.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>14.067213</td>\n      <td>19.247363</td>\n      <td>91.557407</td>\n      <td>648.541099</td>\n      <td>0.096167</td>\n      <td>0.103869</td>\n      <td>0.089193</td>\n      <td>0.048344</td>\n      <td>0.180618</td>\n      <td>0.062820</td>\n      <td>...</td>\n      <td>16.177226</td>\n      <td>25.647297</td>\n      <td>106.625297</td>\n      <td>869.026593</td>\n      <td>0.132329</td>\n      <td>0.254329</td>\n      <td>0.276578</td>\n      <td>0.113904</td>\n      <td>0.290865</td>\n      <td>0.083945</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.499380</td>\n      <td>4.405291</td>\n      <td>24.149231</td>\n      <td>344.944564</td>\n      <td>0.013458</td>\n      <td>0.053522</td>\n      <td>0.081747</td>\n      <td>0.038925</td>\n      <td>0.028074</td>\n      <td>0.007159</td>\n      <td>...</td>\n      <td>4.770020</td>\n      <td>6.225470</td>\n      <td>33.195053</td>\n      <td>552.926912</td>\n      <td>0.022550</td>\n      <td>0.159882</td>\n      <td>0.215937</td>\n      <td>0.066784</td>\n      <td>0.064624</td>\n      <td>0.018408</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>6.981000</td>\n      <td>9.710000</td>\n      <td>43.790000</td>\n      <td>143.500000</td>\n      <td>0.062510</td>\n      <td>0.019380</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.106000</td>\n      <td>0.049960</td>\n      <td>...</td>\n      <td>7.930000</td>\n      <td>12.020000</td>\n      <td>50.410000</td>\n      <td>185.200000</td>\n      <td>0.071170</td>\n      <td>0.027290</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.156500</td>\n      <td>0.055040</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>11.635000</td>\n      <td>16.000000</td>\n      <td>74.720000</td>\n      <td>415.650000</td>\n      <td>0.086475</td>\n      <td>0.063750</td>\n      <td>0.028010</td>\n      <td>0.020220</td>\n      <td>0.161750</td>\n      <td>0.057685</td>\n      <td>...</td>\n      <td>13.010000</td>\n      <td>21.090000</td>\n      <td>83.715000</td>\n      <td>513.900000</td>\n      <td>0.115950</td>\n      <td>0.145850</td>\n      <td>0.107900</td>\n      <td>0.063390</td>\n      <td>0.249400</td>\n      <td>0.071835</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>13.270000</td>\n      <td>18.820000</td>\n      <td>85.980000</td>\n      <td>541.800000</td>\n      <td>0.095660</td>\n      <td>0.090970</td>\n      <td>0.059990</td>\n      <td>0.032630</td>\n      <td>0.178100</td>\n      <td>0.061440</td>\n      <td>...</td>\n      <td>14.910000</td>\n      <td>25.400000</td>\n      <td>97.590000</td>\n      <td>683.400000</td>\n      <td>0.131400</td>\n      <td>0.211600</td>\n      <td>0.229800</td>\n      <td>0.097220</td>\n      <td>0.281900</td>\n      <td>0.079930</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>15.740000</td>\n      <td>21.710000</td>\n      <td>103.700000</td>\n      <td>770.050000</td>\n      <td>0.104850</td>\n      <td>0.130100</td>\n      <td>0.132200</td>\n      <td>0.073820</td>\n      <td>0.195300</td>\n      <td>0.066250</td>\n      <td>...</td>\n      <td>18.550000</td>\n      <td>29.370000</td>\n      <td>124.950000</td>\n      <td>1033.500000</td>\n      <td>0.146200</td>\n      <td>0.336800</td>\n      <td>0.385300</td>\n      <td>0.162500</td>\n      <td>0.320100</td>\n      <td>0.092070</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>28.110000</td>\n      <td>39.280000</td>\n      <td>188.500000</td>\n      <td>2499.000000</td>\n      <td>0.144700</td>\n      <td>0.345400</td>\n      <td>0.426800</td>\n      <td>0.201200</td>\n      <td>0.304000</td>\n      <td>0.097440</td>\n      <td>...</td>\n      <td>33.130000</td>\n      <td>49.540000</td>\n      <td>229.300000</td>\n      <td>3432.000000</td>\n      <td>0.218400</td>\n      <td>1.058000</td>\n      <td>1.252000</td>\n      <td>0.291000</td>\n      <td>0.663800</td>\n      <td>0.207500</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(X_train)\n",
    "df_train.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "               0           1           2            3           4   \\\ncount  114.000000  114.000000  114.000000   114.000000  114.000000   \nmean    14.367079   19.458421   93.611930   680.225439    0.097130   \nstd      3.626623    3.870388   24.928082   379.002396    0.016305   \nmin      7.760000   11.970000   47.920000   181.000000    0.052630   \n25%     11.890000   16.685000   76.375000   434.250000    0.085377   \n50%     13.680000   19.025000   87.910000   571.450000    0.096870   \n75%     16.245000   21.922500  106.525000   811.050000    0.107500   \nmax     27.420000   29.330000  186.900000  2501.000000    0.163400   \n\n               5           6           7           8           9   ...  \\\ncount  114.000000  114.000000  114.000000  114.000000  114.000000  ...   \nmean     0.106225    0.087227    0.051215    0.183332    0.062709  ...   \nstd      0.050065    0.071367    0.038397    0.024598    0.006680  ...   \nmin      0.031160    0.000000    0.000000    0.135300    0.050440  ...   \n25%      0.067132    0.039090    0.022295    0.164250    0.058147  ...   \n50%      0.097620    0.066940    0.041650    0.184350    0.062325  ...   \n75%      0.131525    0.117375    0.073072    0.197375    0.065750  ...   \nmax      0.277000    0.363500    0.187800    0.259500    0.095020  ...   \n\n               20          21          22           23          24  \\\ncount  114.000000  114.000000  114.000000   114.000000  114.000000   \nmean    16.636237   25.796667  109.799298   926.707895    0.132527   \nstd      5.082940    5.844268   35.218674   631.217286    0.024028   \nmin      9.456000   14.100000   59.160000   268.600000    0.088640   \n25%     13.035000   21.022500   85.075000   515.950000    0.120025   \n50%     15.000000   25.430000   98.790000   693.300000    0.131200   \n75%     19.490000   30.377500  128.425000  1145.000000    0.145450   \nmax     36.040000   41.850000  251.200000  4254.000000    0.222600   \n\n               25          26          27          28          29  \ncount  114.000000  114.000000  114.000000  114.000000  114.000000  \nmean     0.254011    0.254668    0.117408    0.286924    0.083951  \nstd      0.147410    0.176207    0.061556    0.049475    0.016683  \nmin      0.052320    0.000000    0.000000    0.199900    0.059330  \n25%      0.148600    0.121400    0.073853    0.253150    0.071180  \n50%      0.217700    0.210650    0.109550    0.282250    0.080535  \n75%      0.342350    0.375800    0.157000    0.307475    0.092165  \nmax      0.868100    0.938700    0.268800    0.475300    0.143100  \n\n[8 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>114.000000</td>\n      <td>114.000000</td>\n      <td>114.000000</td>\n      <td>114.000000</td>\n      <td>114.000000</td>\n      <td>114.000000</td>\n      <td>114.000000</td>\n      <td>114.000000</td>\n      <td>114.000000</td>\n      <td>114.000000</td>\n      <td>...</td>\n      <td>114.000000</td>\n      <td>114.000000</td>\n      <td>114.000000</td>\n      <td>114.000000</td>\n      <td>114.000000</td>\n      <td>114.000000</td>\n      <td>114.000000</td>\n      <td>114.000000</td>\n      <td>114.000000</td>\n      <td>114.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>14.367079</td>\n      <td>19.458421</td>\n      <td>93.611930</td>\n      <td>680.225439</td>\n      <td>0.097130</td>\n      <td>0.106225</td>\n      <td>0.087227</td>\n      <td>0.051215</td>\n      <td>0.183332</td>\n      <td>0.062709</td>\n      <td>...</td>\n      <td>16.636237</td>\n      <td>25.796667</td>\n      <td>109.799298</td>\n      <td>926.707895</td>\n      <td>0.132527</td>\n      <td>0.254011</td>\n      <td>0.254668</td>\n      <td>0.117408</td>\n      <td>0.286924</td>\n      <td>0.083951</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.626623</td>\n      <td>3.870388</td>\n      <td>24.928082</td>\n      <td>379.002396</td>\n      <td>0.016305</td>\n      <td>0.050065</td>\n      <td>0.071367</td>\n      <td>0.038397</td>\n      <td>0.024598</td>\n      <td>0.006680</td>\n      <td>...</td>\n      <td>5.082940</td>\n      <td>5.844268</td>\n      <td>35.218674</td>\n      <td>631.217286</td>\n      <td>0.024028</td>\n      <td>0.147410</td>\n      <td>0.176207</td>\n      <td>0.061556</td>\n      <td>0.049475</td>\n      <td>0.016683</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>7.760000</td>\n      <td>11.970000</td>\n      <td>47.920000</td>\n      <td>181.000000</td>\n      <td>0.052630</td>\n      <td>0.031160</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.135300</td>\n      <td>0.050440</td>\n      <td>...</td>\n      <td>9.456000</td>\n      <td>14.100000</td>\n      <td>59.160000</td>\n      <td>268.600000</td>\n      <td>0.088640</td>\n      <td>0.052320</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.199900</td>\n      <td>0.059330</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>11.890000</td>\n      <td>16.685000</td>\n      <td>76.375000</td>\n      <td>434.250000</td>\n      <td>0.085377</td>\n      <td>0.067132</td>\n      <td>0.039090</td>\n      <td>0.022295</td>\n      <td>0.164250</td>\n      <td>0.058147</td>\n      <td>...</td>\n      <td>13.035000</td>\n      <td>21.022500</td>\n      <td>85.075000</td>\n      <td>515.950000</td>\n      <td>0.120025</td>\n      <td>0.148600</td>\n      <td>0.121400</td>\n      <td>0.073853</td>\n      <td>0.253150</td>\n      <td>0.071180</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>13.680000</td>\n      <td>19.025000</td>\n      <td>87.910000</td>\n      <td>571.450000</td>\n      <td>0.096870</td>\n      <td>0.097620</td>\n      <td>0.066940</td>\n      <td>0.041650</td>\n      <td>0.184350</td>\n      <td>0.062325</td>\n      <td>...</td>\n      <td>15.000000</td>\n      <td>25.430000</td>\n      <td>98.790000</td>\n      <td>693.300000</td>\n      <td>0.131200</td>\n      <td>0.217700</td>\n      <td>0.210650</td>\n      <td>0.109550</td>\n      <td>0.282250</td>\n      <td>0.080535</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>16.245000</td>\n      <td>21.922500</td>\n      <td>106.525000</td>\n      <td>811.050000</td>\n      <td>0.107500</td>\n      <td>0.131525</td>\n      <td>0.117375</td>\n      <td>0.073072</td>\n      <td>0.197375</td>\n      <td>0.065750</td>\n      <td>...</td>\n      <td>19.490000</td>\n      <td>30.377500</td>\n      <td>128.425000</td>\n      <td>1145.000000</td>\n      <td>0.145450</td>\n      <td>0.342350</td>\n      <td>0.375800</td>\n      <td>0.157000</td>\n      <td>0.307475</td>\n      <td>0.092165</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>27.420000</td>\n      <td>29.330000</td>\n      <td>186.900000</td>\n      <td>2501.000000</td>\n      <td>0.163400</td>\n      <td>0.277000</td>\n      <td>0.363500</td>\n      <td>0.187800</td>\n      <td>0.259500</td>\n      <td>0.095020</td>\n      <td>...</td>\n      <td>36.040000</td>\n      <td>41.850000</td>\n      <td>251.200000</td>\n      <td>4254.000000</td>\n      <td>0.222600</td>\n      <td>0.868100</td>\n      <td>0.938700</td>\n      <td>0.268800</td>\n      <td>0.475300</td>\n      <td>0.143100</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(X_text)\n",
    "df_test.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#### The data is not in the same scale, so we need to apply feature scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X_train_std = StandardScaler().fit_transform(X_train)\n",
    "X_test_std = StandardScaler().fit_transform(X_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### View the data after feature scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                 0             1             2             3             4   \\\ncount  4.550000e+02  4.550000e+02  4.550000e+02  4.550000e+02  4.550000e+02   \nmean  -4.337434e-15  2.240942e-15 -7.437274e-16  1.503071e-16  5.223660e-15   \nstd    1.001101e+00  1.001101e+00  1.001101e+00  1.001101e+00  1.001101e+00   \nmin   -2.027220e+00 -2.167362e+00 -1.980187e+00 -1.465734e+00 -2.503730e+00   \n25%   -6.958063e-01 -7.379620e-01 -6.979907e-01 -6.758983e-01 -7.210063e-01   \n50%   -2.280663e-01 -9.711800e-02 -2.312101e-01 -3.097848e-01 -3.774691e-02   \n75%    4.785500e-01  5.596334e-01  5.033684e-01  3.526440e-01  6.458845e-01   \nmax    4.017353e+00  4.552410e+00  4.018733e+00  5.370416e+00  3.610271e+00   \n\n                 5             6             7             8             9   \\\ncount  4.550000e+02  4.550000e+02  4.550000e+02  4.550000e+02  4.550000e+02   \nmean  -2.775802e-15 -7.046866e-16  6.031805e-16 -3.263812e-15 -3.031519e-15   \nstd    1.001101e+00  1.001101e+00  1.001101e+00  1.001101e+00  1.001101e+00   \nmin   -1.580330e+00 -1.092292e+00 -1.243358e+00 -2.660791e+00 -1.798182e+00   \n25%   -7.504076e-01 -7.492716e-01 -7.233200e-01 -6.728116e-01 -7.179958e-01   \n50%   -2.412686e-01 -3.576338e-01 -4.041472e-01 -8.978972e-02 -1.929345e-01   \n75%    4.906419e-01  5.266743e-01  6.552186e-01  5.235422e-01  4.796473e-01   \nmax    4.517740e+00  4.134445e+00  3.931305e+00  4.399657e+00  4.840942e+00   \n\n       ...            20            21            22            23  \\\ncount  ...  4.550000e+02  4.550000e+02  4.550000e+02  4.550000e+02   \nmean   ...  4.060244e-16  5.676534e-15 -2.402962e-15 -1.022869e-15   \nstd    ...  1.001101e+00  1.001101e+00  1.001101e+00  1.001101e+00   \nmin    ... -1.730874e+00 -2.191368e+00 -1.695348e+00 -1.238101e+00   \n25%    ... -6.647169e-01 -7.328464e-01 -6.909317e-01 -6.429737e-01   \n50%    ... -2.659572e-01 -3.976710e-02 -2.724877e-01 -3.360859e-01   \n75%    ...  4.979823e-01  5.986377e-01  5.526388e-01  2.977870e-01   \nmax    ...  3.557938e+00  3.842120e+00  3.699640e+00  4.640386e+00   \n\n                 24            25            26            27            28  \\\ncount  4.550000e+02  4.550000e+02  4.550000e+02  4.550000e+02  4.550000e+02   \nmean   4.172487e-15 -5.465713e-16 -6.383172e-16 -4.489693e-16 -1.034581e-15   \nstd    1.001101e+00  1.001101e+00  1.001101e+00  1.001101e+00  1.001101e+00   \nmin   -2.715107e+00 -1.421602e+00 -1.282241e+00 -1.707442e+00 -2.081459e+00   \n25%   -7.271308e-01 -6.792384e-01 -7.820068e-01 -7.572169e-01 -6.423407e-01   \n50%   -4.123889e-02 -2.675449e-01 -2.168678e-01 -2.501005e-01 -1.388815e-01   \n75%    6.157967e-01  5.163947e-01  5.040438e-01  7.284559e-01  4.528766e-01   \nmax    3.821065e+00  5.032188e+00  4.522140e+00  2.654689e+00  5.777151e+00   \n\n                 29  \ncount  4.550000e+02  \nmean  -2.088683e-15  \nstd    1.001101e+00  \nmin   -1.571972e+00  \n25%   -6.585793e-01  \n50%   -2.183342e-01  \n75%    4.418976e-01  \nmax    6.719538e+00  \n\n[8 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4.550000e+02</td>\n      <td>4.550000e+02</td>\n      <td>4.550000e+02</td>\n      <td>4.550000e+02</td>\n      <td>4.550000e+02</td>\n      <td>4.550000e+02</td>\n      <td>4.550000e+02</td>\n      <td>4.550000e+02</td>\n      <td>4.550000e+02</td>\n      <td>4.550000e+02</td>\n      <td>...</td>\n      <td>4.550000e+02</td>\n      <td>4.550000e+02</td>\n      <td>4.550000e+02</td>\n      <td>4.550000e+02</td>\n      <td>4.550000e+02</td>\n      <td>4.550000e+02</td>\n      <td>4.550000e+02</td>\n      <td>4.550000e+02</td>\n      <td>4.550000e+02</td>\n      <td>4.550000e+02</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-4.337434e-15</td>\n      <td>2.240942e-15</td>\n      <td>-7.437274e-16</td>\n      <td>1.503071e-16</td>\n      <td>5.223660e-15</td>\n      <td>-2.775802e-15</td>\n      <td>-7.046866e-16</td>\n      <td>6.031805e-16</td>\n      <td>-3.263812e-15</td>\n      <td>-3.031519e-15</td>\n      <td>...</td>\n      <td>4.060244e-16</td>\n      <td>5.676534e-15</td>\n      <td>-2.402962e-15</td>\n      <td>-1.022869e-15</td>\n      <td>4.172487e-15</td>\n      <td>-5.465713e-16</td>\n      <td>-6.383172e-16</td>\n      <td>-4.489693e-16</td>\n      <td>-1.034581e-15</td>\n      <td>-2.088683e-15</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.001101e+00</td>\n      <td>1.001101e+00</td>\n      <td>1.001101e+00</td>\n      <td>1.001101e+00</td>\n      <td>1.001101e+00</td>\n      <td>1.001101e+00</td>\n      <td>1.001101e+00</td>\n      <td>1.001101e+00</td>\n      <td>1.001101e+00</td>\n      <td>1.001101e+00</td>\n      <td>...</td>\n      <td>1.001101e+00</td>\n      <td>1.001101e+00</td>\n      <td>1.001101e+00</td>\n      <td>1.001101e+00</td>\n      <td>1.001101e+00</td>\n      <td>1.001101e+00</td>\n      <td>1.001101e+00</td>\n      <td>1.001101e+00</td>\n      <td>1.001101e+00</td>\n      <td>1.001101e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-2.027220e+00</td>\n      <td>-2.167362e+00</td>\n      <td>-1.980187e+00</td>\n      <td>-1.465734e+00</td>\n      <td>-2.503730e+00</td>\n      <td>-1.580330e+00</td>\n      <td>-1.092292e+00</td>\n      <td>-1.243358e+00</td>\n      <td>-2.660791e+00</td>\n      <td>-1.798182e+00</td>\n      <td>...</td>\n      <td>-1.730874e+00</td>\n      <td>-2.191368e+00</td>\n      <td>-1.695348e+00</td>\n      <td>-1.238101e+00</td>\n      <td>-2.715107e+00</td>\n      <td>-1.421602e+00</td>\n      <td>-1.282241e+00</td>\n      <td>-1.707442e+00</td>\n      <td>-2.081459e+00</td>\n      <td>-1.571972e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-6.958063e-01</td>\n      <td>-7.379620e-01</td>\n      <td>-6.979907e-01</td>\n      <td>-6.758983e-01</td>\n      <td>-7.210063e-01</td>\n      <td>-7.504076e-01</td>\n      <td>-7.492716e-01</td>\n      <td>-7.233200e-01</td>\n      <td>-6.728116e-01</td>\n      <td>-7.179958e-01</td>\n      <td>...</td>\n      <td>-6.647169e-01</td>\n      <td>-7.328464e-01</td>\n      <td>-6.909317e-01</td>\n      <td>-6.429737e-01</td>\n      <td>-7.271308e-01</td>\n      <td>-6.792384e-01</td>\n      <td>-7.820068e-01</td>\n      <td>-7.572169e-01</td>\n      <td>-6.423407e-01</td>\n      <td>-6.585793e-01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-2.280663e-01</td>\n      <td>-9.711800e-02</td>\n      <td>-2.312101e-01</td>\n      <td>-3.097848e-01</td>\n      <td>-3.774691e-02</td>\n      <td>-2.412686e-01</td>\n      <td>-3.576338e-01</td>\n      <td>-4.041472e-01</td>\n      <td>-8.978972e-02</td>\n      <td>-1.929345e-01</td>\n      <td>...</td>\n      <td>-2.659572e-01</td>\n      <td>-3.976710e-02</td>\n      <td>-2.724877e-01</td>\n      <td>-3.360859e-01</td>\n      <td>-4.123889e-02</td>\n      <td>-2.675449e-01</td>\n      <td>-2.168678e-01</td>\n      <td>-2.501005e-01</td>\n      <td>-1.388815e-01</td>\n      <td>-2.183342e-01</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.785500e-01</td>\n      <td>5.596334e-01</td>\n      <td>5.033684e-01</td>\n      <td>3.526440e-01</td>\n      <td>6.458845e-01</td>\n      <td>4.906419e-01</td>\n      <td>5.266743e-01</td>\n      <td>6.552186e-01</td>\n      <td>5.235422e-01</td>\n      <td>4.796473e-01</td>\n      <td>...</td>\n      <td>4.979823e-01</td>\n      <td>5.986377e-01</td>\n      <td>5.526388e-01</td>\n      <td>2.977870e-01</td>\n      <td>6.157967e-01</td>\n      <td>5.163947e-01</td>\n      <td>5.040438e-01</td>\n      <td>7.284559e-01</td>\n      <td>4.528766e-01</td>\n      <td>4.418976e-01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.017353e+00</td>\n      <td>4.552410e+00</td>\n      <td>4.018733e+00</td>\n      <td>5.370416e+00</td>\n      <td>3.610271e+00</td>\n      <td>4.517740e+00</td>\n      <td>4.134445e+00</td>\n      <td>3.931305e+00</td>\n      <td>4.399657e+00</td>\n      <td>4.840942e+00</td>\n      <td>...</td>\n      <td>3.557938e+00</td>\n      <td>3.842120e+00</td>\n      <td>3.699640e+00</td>\n      <td>4.640386e+00</td>\n      <td>3.821065e+00</td>\n      <td>5.032188e+00</td>\n      <td>4.522140e+00</td>\n      <td>2.654689e+00</td>\n      <td>5.777151e+00</td>\n      <td>6.719538e+00</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_std = pd.DataFrame(X_train_std)\n",
    "df_train_std.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Use the k-fold cross validation to evaluate the Decision Tree model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies =  [0.9560439560439561, 0.945054945054945, 0.945054945054945, 0.9230769230769231, 0.8791208791208791]\n",
      "bestHyperParameter =  10\n"
     ]
    }
   ],
   "source": [
    "k_outer = 5\n",
    "k_inner = 5\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "best_hyper_parameter = []\n",
    "\n",
    "outer_cv = KFold(n_splits=k_outer, shuffle=True, random_state=42)\n",
    "for train_index, validation_index in outer_cv.split(X_train_std):\n",
    "    X_train_outer, X_validation_outer = X_train_std[train_index], X_train_std[validation_index]\n",
    "    y_train_outer, y_validation_outer = y_train[train_index], y_train[validation_index]\n",
    "\n",
    "    bestAccuracy = 0\n",
    "    bestHyperParameter = None\n",
    "\n",
    "    for max_depth in range(10, 101, 10):\n",
    "        inner_accuracies = []\n",
    "\n",
    "        inner_cv = KFold(n_splits=k_inner, shuffle=True, random_state=42)\n",
    "        for train_index, validation_index in inner_cv.split(X_train_outer):\n",
    "            X_train_inner, X_validation_inner = X_train_outer[train_index], X_train_outer[validation_index]\n",
    "            y_train_inner, y_validation_inner = y_train_outer[train_index], y_train_outer[validation_index]\n",
    "\n",
    "            classifier = DecisionTreeClassifier(criterion='entropy', max_depth=max_depth, random_state=42)\n",
    "            classifier.fit(X_train_inner, y_train_inner)\n",
    "\n",
    "            y_pred = classifier.predict(X_validation_inner)\n",
    "            inner_accuracies.append(accuracy_score(y_validation_inner, y_pred))\n",
    "\n",
    "        meanAccuracy = np.mean(inner_accuracies)\n",
    "\n",
    "        if meanAccuracy > bestAccuracy:\n",
    "            bestAccuracy = meanAccuracy\n",
    "            bestHyperParameter = max_depth\n",
    "\n",
    "    finalClassifier = DecisionTreeClassifier(criterion='entropy', max_depth=bestHyperParameter, random_state=42)\n",
    "    finalClassifier.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "    y_pred = finalClassifier.predict(X_validation_outer)\n",
    "    accuracy = accuracy_score(y_validation_outer, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    best_hyper_parameter.append(bestHyperParameter)\n",
    "\n",
    "\n",
    "meanAccuracy = np.mean(accuracies)\n",
    "\n",
    "print(\"accuracies = \", accuracies)\n",
    "\n",
    "bestHyperParameter = max(set(best_hyper_parameter), key=best_hyper_parameter.count)\n",
    "print(\"bestHyperParameter = \", bestHyperParameter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Use the k-fold cross validation to evaluate the KNN model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanAccuracy =  0.9626373626373628\n",
      "accuracies =  [0.9560439560439561, 0.989010989010989, 0.978021978021978, 0.967032967032967, 0.9230769230769231]\n",
      "bestHyperParameter =  3\n"
     ]
    }
   ],
   "source": [
    "k_outer = 5\n",
    "k_inner = 5\n",
    "\n",
    "accuracies = []\n",
    "best_hyper_parameter = []\n",
    "hyperParamterK = [1, 3, 5, 11, 21, 31]\n",
    "\n",
    "outer_cv = KFold(n_splits=k_outer, shuffle=True, random_state=42)\n",
    "for train_index, validation_index in outer_cv.split(X_train_std):\n",
    "    X_train_outer, X_validation_outer = X_train_std[train_index], X_train_std[validation_index]\n",
    "    y_train_outer, y_validation_outer = y_train[train_index], y_train[validation_index]\n",
    "\n",
    "    bestAccuracy = 0\n",
    "    bestHyperParameter = None\n",
    "\n",
    "    for kValue in hyperParamterK:\n",
    "        inner_accuracies = []\n",
    "\n",
    "        inner_cv = KFold(n_splits=k_inner, shuffle=True, random_state=42)\n",
    "        for train_index, validation_index in inner_cv.split(X_train_outer):\n",
    "            X_train_inner, X_validation_inner = X_train_outer[train_index], X_train_outer[validation_index]\n",
    "            y_train_inner, y_validation_inner = y_train_outer[train_index], y_train_outer[validation_index]\n",
    "\n",
    "            classifier = KNeighborsClassifier(n_neighbors=kValue, metric='minkowski', p=2)\n",
    "            classifier.fit(X_train_inner, y_train_inner)\n",
    "\n",
    "            y_pred = classifier.predict(X_validation_inner)\n",
    "            inner_accuracies.append(accuracy_score(y_validation_inner, y_pred))\n",
    "\n",
    "        meanAccuracy = np.mean(inner_accuracies)\n",
    "\n",
    "        if meanAccuracy > bestAccuracy:\n",
    "            bestAccuracy = meanAccuracy\n",
    "            bestHyperParameter = kValue\n",
    "\n",
    "    finalClassifier = KNeighborsClassifier(n_neighbors=bestHyperParameter, metric='minkowski', p=2)\n",
    "    finalClassifier.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "    y_pred = finalClassifier.predict(X_validation_outer)\n",
    "    accuracy = accuracy_score(y_validation_outer, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    best_hyper_parameter.append(bestHyperParameter)\n",
    "\n",
    "meanAccuracy = np.mean(accuracies)\n",
    "print(\"meanAccuracy = \", meanAccuracy)\n",
    "print(\"accuracies = \", accuracies)\n",
    "\n",
    "bestHyperParameter = max(set(best_hyper_parameter), key=best_hyper_parameter.count)\n",
    "print(\"bestHyperParameter = \", bestHyperParameter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Choose the best model and predict the test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=3, metric='minkowski', p=2)\n",
    "classifier.fit(X_train_std, y_train)\n",
    "y_pred = classifier.predict(X_test_std)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluate the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy = \", accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cm =  [[39  3]\n",
      " [ 0 72]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"cm = \", cm)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
